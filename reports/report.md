# Семестровая работа по дисциплене "Машинное обучение"

# Тема : "_Распознование цифр_"

### Выполнил
Плискин Александр Маркович  
Высшая школа ИТИС  
группа 11-401
### Руководитель
Новиков Пётр Андреевич

________________________________________

#1.Описание набора данных

## Digits recognizer for MNIST data

1. Мною была выбрана задача https://www.kaggle.com/c/digit-recognizer
Используя MNIST данные нужно будет распознать и классифицировать фотографии цифр.

2. Данные представляют собой двумерный массив. Каждое изображение представляет из себя матрицу 28х28 пикселей.
Значениями ячеек(значение каждого пикселя) явлются числа от 0 до 255, которые обозначают "темноту" пикселя(0 - белый или пустой, 255 - абсолютно черный, 122 - серый)
Обучающий набор состоит из 42000 цифр. Если быть точнее то обучающим набором является матрица 42000х785
в первом столбце стоит "label" - изображенная цифра, остальное - значения пикселей
Данными для распознования является матрица размером 28000х784. В ней уже 28000 цифр, и отсутсвует столбец, обозначающий "label"(изображенную цифру)

________________________________________

#2.Преобразования с данными

## Data processing

 Для считывания данных из csv-файла использую библиотеку pandas.
 При помощи метода read_csv('<file_name>.csv') преобразую данные csv-файла в массив и передаю его в значение переменной.

 Данные представлены в виде матрицы из 42000 тысяч экземплров чисел.
 Каждый экземпляр состоит из 785 ячеек.
 При помощи пакета управления массивами numpy преобразую каждый такой экземпляр в массив из 784 ячеек(кроме первой, она является "лэйблом"), значение каждой из которых делю на 255.
 В итоге для каждой цифры в данных для обучения получаю массив со значениями от 0 до 1, которые обозначают жирность ячейки(или темноту)

 Отдельно создаю массив лэйблов - самый первый(у программистов нулевой) элемент(ячейка) массива каждого учебного экземпляра.


## Data view

 Для визуализации использую пакет matploitlib. Подаю в него матрицу рамером 28х28 и вывожу в график.

________________________________________

#3.Методы машинного обучения

Задача классификации в машинном обучении — это задача отнесения объекта к одному из заранее определенных классов на основании его формализованных признаков. Каждый из объектов в этой задаче представляется в виде вектора в N-мерном пространстве, каждое измерение в котором представляет собой описание одного из признаков объекта.
Для распознования цифр в работе используются классификаторы из библиотеки skikit-learn.

### Классификатор kNN

#### Алгоритм

Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:
Вычислить расстояние до каждого из объектов обучающей выборки
Отобрать k объектов обучающей выборки, расстояние до которых минимально
Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди k ближайших соседей

kNN — один из простейших алгоритмов классификации, поэтому на реальных задачах он зачастую оказывается неэффективным. Помимо точности классификации, проблемой этого классификатора является скорость классификации: если в обучающей выборке N объектов, в тестовой выборе M объектов, а размерность пространства — K, то количество операций для классификации тестовой выборки может быть оценено как O(K*M*N).


### Бинарное дерево решений



### Дерево принятия решений

на каждой итерации делается случайная выборка переменных, после чего, на этой новой выборке запускают построение дерева принятия решений. При этом производится “bagging” — выборка случайных двух третей наблюдений для обучения, а оставшаяся треть используется для оценки результата. Такую операцию проделывают сотни или тысячи раз. Результирующая модель будет будет результатом “голосования” набора полученных при моделировании деревьев.
+ Высокое качество результата, особенно для данных с большим количеством переменных и малым количеством наблюдений.
+ Возможность распараллелить
+ Не требуется тестовая выборка
- Каждое из деревьев огромное, в результате модель получается огромная
- Долгое построение модели, для достижения хороших результатов.
- Сложная интерпретация модели (Сотни или тысячи больших деревьев сложны для интерпретации)



________________________________________

#4.Оценка точности и временных затрат

##1. Временные затраты
Время измеряется в секундах

##2. Точность результатов
###точность расчитывается следующим образом:
 каждая метка из спрогнозированного множества должна соответствовать метке из множества решений.

### Для проверки точности будет взято

1. 34.000 представлений цифр
2. 21.000 представлений цифр
3. 1.000 представлений цифр

### Сводная таблица результатов 1

|Классификатор|Время(42000 экземпляров)|Точность1|Точность2|Точность3|
|---|---|---|---|---|
|Decision Tree|14.52|85.25|83.79|67.63|
|Random Forest|30.52|93.53|92.74|79.81|

#### Классификатор KNeighbors не использовался для получения предсказания, так как трубует слишком большого времени для обучения на большом объеме данных.
Если же взять количество учебных данных в размере 1000 цифр, для предсказания у него уходит в ~2500 больше времени, при этом точность немного выше, чем у Random Tree Classifier:

### Свобная таблица результатов 2

|Классификатор|Время(42000 экземпляров)|Точность|
|---|---|---|
KNeighbors classifier| 51.46885013580322 секунд | 87.6097560976
Bayes classifier| 0.1552278995513916 секунд | 67.6341463415
Random forest classifier| 0.20938992500305176 секунд | 79.8097560976

##Вывод
Для получения одновременно надежного и быстрого предсказания стоит использовать классификатор RandomFоrest из библиотеки sklearn


    
________________________________________